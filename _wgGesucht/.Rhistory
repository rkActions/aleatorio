print("file exists reading...")
}
outpath
outpath = here("analysis/wgs.csv")
if(!file.exists(outpath)) {
print("file does not exist")
df = data.frame(
price = NA,
location = NA,
id = NA,
size = NA,
wg = NA
)
write.csv(df, outpath)
} else{
df = read.csv(outpath)
print("file exists reading...")
}
end = findId()
end
df[["date"]] = as.Date(df$date)
# date --------------------------------------------------------------------
today = Sys.Date()
# get the ids -------------------------------------------------------------
page_ids = (end+20):(end-30)
rows = vector("list", length=length(page_ids))
for(i in seq_along(page_ids)){
print(i)
id = page_ids[[i]]
url = paste0("https://www.wg-gesucht.de/", id, ".html" )
file = paste0(tempfile(), ".html")
# download
download.file(url, file)
# read
html = rvest::read_html(file)
size = getSize(html) %>% as.numeric()
price = getPrice(html) %>% as.numeric()
location = getLocation(html) %>% as.character()
wg = getWG(file)
print(paste0("WG: ", wg))
row = list(price = price, size = size, location = location, id = id, wg=wg, date=today)
rows[[i]] = row
}
# create dataframe --------------------------------------------------------
df_new = bind_rows(rows)
df_new
# geocode -----------------------------------------------------------------
df_new_geo = df_new %>%
geocode(location)
# bind them together ------------------------------------------------------
df_final = bind_rows(df, df_new_geo)
# write out ---------------------------------------------------------------
write.csv(df_final, outpath, row.names = F)
# calculate how many wgsjj:w ----------------------------------------------
data = read.csv(outpath)
data
noNa = data %>%
filter(!is.na(price))
noNaWg = noNa %>%
filter(wg == T)
df = data.frame(
date = Sys.time(),
noNaAndWg = nrow(noNaWg)
)
df
outpath_n = here("analysis/nwgs.csv")
outdir = dirname(outpath_n)
if(!file.exists(outpath_n)){
write.csv(df, outpath_n, row.names = F)
}else{
df_old = read.csv(outpath_n)
df_new = rbind(df, df_old)
write.csv(df_new, outpath_n, row.names = F)
}
library(rvest)
library(glue)
library(dplyr)
library(stringr)
library(tidygeocoder)
source(here("analysis/utils.R"))
library(here)
source(here("analysis/utils.R"))
outpath = here("analysis/wgs.csv")
if(!file.exists(outpath)) {
print("file does not exist")
df = data.frame(
price = NA,
location = NA,
id = NA,
size = NA,
wg = NA
)
write.csv(df, outpath)
} else{
df = read.csv(outpath)
print("file exists reading...")
}
df
df %>% glimpse
if(!file.exists(outpath)) {
print("file does not exist")
df = data.frame(
price = NA,
location = NA,
id = NA,
size = NA,
wg = NA
)
write.csv(df, outpath)
} else{
df = read.csv(outpath)
print("file exists reading...")
}
df
df %>% glimpse
df = read_csv(outpath)
df[["date"]] = as.Date(df[["date"]])
df
df %>% glimpse
# date --------------------------------------------------------------------
today = Sys.Date()
# get the ids -------------------------------------------------------------
page_ids = (end+30):(end-30)
rows = vector("list", length=length(page_ids))
for(i in seq_along(page_ids)){
print(i)
id = page_ids[[i]]
url = paste0("https://www.wg-gesucht.de/", id, ".html" )
file = paste0(tempfile(), ".html")
# download
download.file(url, file)
# read
html = rvest::read_html(file)
size = getSize(html) %>% as.numeric()
price = getPrice(html) %>% as.numeric()
location = getLocation(html) %>% as.character()
wg = getWG(file)
print(paste0("WG: ", wg))
row = list(price = price, size = size, location = location, id = id, wg=wg, date=today)
rows[[i]] = row
}
# date --------------------------------------------------------------------
today = Sys.Date()
# get the ids -------------------------------------------------------------
page_ids = (end+30):(end-30)
emd
end
# find the end id
end = findId()
df[["date"]] = as.Date(df[["date"]])
# date --------------------------------------------------------------------
today = Sys.Date()
# get the ids -------------------------------------------------------------
page_ids = (end+30):(end-30)
page_ids
rows = vector("list", length=length(page_ids))
for(i in seq_along(page_ids)){
print(i)
id = page_ids[[i]]
url = paste0("https://www.wg-gesucht.de/", id, ".html" )
file = paste0(tempfile(), ".html")
# download
download.file(url, file)
# read
html = rvest::read_html(file)
size = getSize(html) %>% as.numeric()
price = getPrice(html) %>% as.numeric()
location = getLocation(html) %>% as.character()
wg = getWG(file)
print(paste0("WG: ", wg))
row = list(price = price, size = size, location = location, id = id, wg=wg, date=today)
rows[[i]] = row
}
# create dataframe --------------------------------------------------------
df_new = bind_rows(rows)
df_new
# geocode -----------------------------------------------------------------
df_new_geo = df_new %>%
geocode(location)
# bind them together ------------------------------------------------------
df_final = bind_rows(df, df_new_geo)
# write out ---------------------------------------------------------------
write.csv(df_final, outpath, row.names = F)
# calculate how many wgsjj:w ----------------------------------------------
data = read.csv(outpath)
noNa = data %>%
filter(!is.na(price))
noNaWg = noNa %>%
filter(wg == T)
df = data.frame(
date = Sys.time(),
noNaAndWg = nrow(noNaWg)
)
df
outpath_n = here("analysis/nwgs.csv")
outdir = dirname(outpath_n)
if(!file.exists(outpath_n)){
write.csv(df, outpath_n, row.names = F)
}else{
df_old = read.csv(outpath_n)
df_new = rbind(df, df_old)
write.csv(df_new, outpath_n, row.names = F)
}
html %>%
html_elements(".section_panel_detail")
html
id
id = 10600253
url = paste0("https://www.wg-gesucht.de/", id, ".html" )
file = paste0(tempfile(), ".html")
# download
download.file(url, file)
# read
html = rvest::read_html(file)
html %>%
html_elements(".section_panel_detail")
html
html %>%
html_elements(".section_panel_value")
html %>%
html_element(".section_panel_value")
html %>%
html_elements(".section_panel_value")
url
id
html
url = paste0("https://www.wg-gesucht.de/", id, ".html" )
file = paste0(tempfile(), ".html")
# download
download.file(url, file)
# read
html = rvest::read_html(file)
html %>%
html_elements(".section_panel_value")
section_panel_details = html %>%
html_elements(".section_panel_value")
section_panel_details %>% html_text()
section_panel_details = html %>%
html_elements(".section_panel_detail")
section_panel_details
section_panel_details = html %>%
html_elements(".section_panel_detail") %>%
html_text()
section_panel_details
section_panel_details = html %>%
html_elements(".section_panel_detail") %>%
html_text(trim = T)
section_panel_details
section_panel_details = html %>%
html_elements(".section_panel_detail") %>%
html_text(trim = T) %>%
str_replace("\\s{2,}", " ")
section_panel_details
frei_ab_index = str_detect(section_panel_details, "frei ab")
frei_ab_index
frei_ab_index = which(str_detect(section_panel_details, "frei ab"))
frei_ab_index
section_panel_values = html %>%
html_elements(".section_panel_value") %>%
html_text(trim = T) %>%
str_replace("\\s{2,}", " ")
section_panel_values
frei_ab_value = section_panel_values[[frei_ab_index]]
frei_ab_index = which(str_detect(section_panel_details, "frei ab"))
frei_ab_value = section_panel_values[[frei_ab_index]]
frei_ab_value = section_panel_values[frei_ab_index]
frei_ab_value
section_panel_values
section_panel_details
section_panel_values = html %>%
html_elements(".section_panel_value") %>%
html_text(trim = T) %>%
str_replace("\\s{2,}", " ")
section_panel_values
as.Date(section_panel_values)
html %>%
html_elements(".col-xs-12 col-sm-6")
html %>%
html_elements(".col-xs-12.col-sm-6")
sections = html %>%
html_elements(".col-xs-12.col-sm-6")
sections
x = sections[[1]]
x
x %>%
html_elements("h3")
map(sections, function(x){
t = x %>%
html_elements("h3") %>%
html_text(trim = T)
if(t == "Verfügbarkeit"){
return(x)
}
return(NA)
})
library(purrr)
lapply(sections, function(x){
t = x %>%
html_elements("h3") %>%
html_text(trim = T)
if(t == "Verfügbarkeit"){
return(x)
}
return(NA)
})
x
t = x %>%
html_elements("h3") %>%
html_text(trim = T)
t
lapply(sections, function(x){
t = x %>%
html_elements("h3") %>%
html_text(trim = T)
if(length(t) > 0 && t == "Verfügbarkeit"){
return(x)
}
return(NA)
})
sections
sections_inner = lapply(sections, function(x){
t = x %>%
html_elements("h3") %>%
html_text(trim = T)
if(length(t) > 0 && t == "Verfügbarkeit"){
return(x)
}
return(NA)
})
section_verf = sections_inner[[!is.na(sections_inner)]]
is.na(sectinos_inner)
is.na(sections_inner)
section_verf = sections_inner[!is.na(sections_inner)]
section_verf
section_verf = sections_inner[!is.na(sections_inner)][[1]]
section_verf
section_panel_details = section_verf %>%
html_elements(".section_panel_detail") %>%
html_text(trim = T) %>%
str_replace("\\s{2,}", " ")
section_panel_details
section_panel_values = html %>%
html_elements(".section_panel_value") %>%
html_text(trim = T) %>%
str_replace("\\s{2,}", " ")
section_panel_values
section_panel_values = section_verf %>%
html_elements(".section_panel_value") %>%
html_text(trim = T) %>%
str_replace("\\s{2,}", " ")
section_panel_values
section_panel_details
ab_idx = str_detect(section_panel_details, "frei ab")
ab_idx
ab_val = section_panel_values[[ab_idx]]
ab_val = section_panel_values[ab_idx]
ab_val
bis_val = section_panel_values[bis_idx]
bis_idx = which(str_detect(section_panel_details, "frei bis"))
ab_val = section_panel_values[ab_idx]
bis_val = section_panel_values[bis_idx]
bis_val
return(list(ab=ab_val, bis=bis_idx))
source(here("analysis/utils.R"))
ab_bis = freiAb(html)
ab_bis
source(here("analysis/utils.R"))
ab_bis = freiAb(html)
ab_bis
i = 1
print(i)
id = page_ids[[i]]
url = paste0("https://www.wg-gesucht.de/", id, ".html" )
file = paste0(tempfile(), ".html")
# download
download.file(url, file)
# read
html = rvest::read_html(file)
size = getSize(html) %>% as.numeric()
price = getPrice(html) %>% as.numeric()
price
ab_bis = freiAb(html)
sections = html %>%
html_elements(".col-xs-12.col-sm-6")
sections_inner = lapply(sections, function(x){
t = x %>%
html_elements("h3") %>%
html_text(trim = T)
if(length(t) > 0 && t == "Verfügbarkeit"){
return(x)
}
return(NA)
})
section_verf = sections_inner[!is.na(sections_inner)][[1]]
sections_inner
source(here("analysis/utils.R"))
ab_bis = freiAb(html)
ab_bis
ab = ab_bis$ab
bis = ab_bis$bis
location = getLocation(html) %>% as.character()
wg = getWG(file)
print(paste0("WG: ", wg))
row = list(price = price, size = size, location = location, id = id, wg=wg, date=today, ab=ab, bis=bis)
row
library(rvest)
library(glue)
library(dplyr)
library(stringr)
library(tidygeocoder)
# source ------------------------------------------------------------------
source("_wgGesucht/analysis/utils.R")
source(here("analysis/utils.R"))
outpath = here("analysis/wgs.csv")
# outfile -----------------------------------------------------------------
outpath = "_wgGesucht/analysis/wgs.csv"
if(!file.exists(outpath)) {
print("file does not exist")
df = data.frame(
price = NA,
location = NA,
id = NA,
size = NA,
wg = NA
)
write.csv(df, outpath)
} else{
df = read.csv(outpath)
print("file exists reading...")
}
if(!file.exists(outpath)) {
print("file does not exist")
df = data.frame(
price = NA,
location = NA,
id = NA,
size = NA,
wg = NA
)
write.csv(df, outpath)
} else{
df = read.csv(outpath)
print("file exists reading...")
}
outpath
outpath = here("analysis/wgs.csv")
outpath
if(!file.exists(outpath)) {
print("file does not exist")
df = data.frame(
price = NA,
location = NA,
id = NA,
size = NA,
wg = NA
)
write.csv(df, outpath)
} else{
df = read.csv(outpath)
print("file exists reading...")
}
# find the end id
end = findId()
df[["date"]] = as.Date(df[["date"]])
# date --------------------------------------------------------------------
today = Sys.Date()
# get the ids -------------------------------------------------------------
page_ids = (end+50):(end-100)
rows = vector("list", length=length(page_ids))
for(i in seq_along(page_ids)){
print(i)
id = page_ids[[i]]
url = paste0("https://www.wg-gesucht.de/", id, ".html" )
file = paste0(tempfile(), ".html")
# download
download.file(url, file)
# read
html = rvest::read_html(file)
size = getSize(html) %>% as.numeric()
price = getPrice(html) %>% as.numeric()
ab_bis = freiAb(html)
ab = ab_bis$ab
bis = ab_bis$bis
location = getLocation(html) %>% as.character()
wg = getWG(file)
print(paste0("WG: ", wg))
row = list(price = price, size = size, location = location, id = id, wg=wg, date=today, ab=ab, bis=bis)
rows[[i]] = row
}
# get the ids -------------------------------------------------------------
page_ids = (end+50):(end-50)
rows = vector("list", length=length(page_ids))
for(i in seq_along(page_ids)){
print(i)
id = page_ids[[i]]
url = paste0("https://www.wg-gesucht.de/", id, ".html" )
file = paste0(tempfile(), ".html")
# download
download.file(url, file)
# read
html = rvest::read_html(file)
size = getSize(html) %>% as.numeric()
price = getPrice(html) %>% as.numeric()
ab_bis = freiAb(html)
ab = ab_bis$ab
bis = ab_bis$bis
location = getLocation(html) %>% as.character()
wg = getWG(file)
print(paste0("WG: ", wg))
row = list(price = price, size = size, location = location, id = id, wg=wg, date=today, ab=ab, bis=bis)
rows[[i]] = row
}
