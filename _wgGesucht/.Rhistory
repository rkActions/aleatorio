filter(str_detect(name, "x")) %>%
count(name, sort=T)
?babynames
count
?count
babynames %>%
group_by(year) %>%
summarise(
mean_prop = mean(str_detect(name, "x"))
) %>%
ggplot() +
geom_line(
aes(
year,
mean_prop
)
)
babynames %>%
group_by(year) %>%
summarise(
mean_prop = mean(str_detect(name, "x"))
)
babynames %>%
group_by(year) %>%
summarise(
mean_prop = mean(str_detect(name, "y"))
) %>%
ggplot() +
geom_line(
aes(
year,
mean_prop
)
)
babynames %>%
group_by(year) %>%
summarise(
mean_prop = mean(str_detect(name, "a"))
) %>%
ggplot() +
geom_line(
aes(
year,
mean_prop
)
)
babynames %>%
group_by(year) %>%
summarise(
mean_prop = mean(str_detect(name, "s"))
) %>%
ggplot() +
geom_line(
aes(
year,
mean_prop
)
)
babynames %>%
group_by(year) %>%
summarise(
mean_prop = mean(str_detect(name, "ad"))
) %>%
ggplot() +
geom_line(
aes(
year,
mean_prop
)
)
babynames %>%
group_by(year) %>%
summarise(
mean_prop = mean(str_detect(name, "ss"))
) %>%
ggplot() +
geom_line(
aes(
year,
mean_prop
)
)
babynames %>%
mutate(
vowels = str_count(name, "[^aeiou]")
)
babynames %>%
mutate(
consonants = str_count(name, "[^aeiou]"),
vowels = str_count(name, "[aeiou]")
)
babynames %>%
mutate(
name = str_to_lower(name),
consonants = str_count(name, "[^aeiou]"),
vowels = str_count(name, "[aeiou]")
)
df <- tribble(
~str,
"<Sheryl>-F_34",
"<Kisha>-F_45",
"<Brandon>-N_33",
"<Sharon>-F_38",
"<Penny>-F_58",
"<Justin>-M_41",
"<Patricia>-F_84",
)
df
sentences
install.packages("camcorder")
library(tidyverse)
library(rvest)
library(glue)
# source ------------------------------------------------------------------
source("_wgGesucht/analysis/utils.R")
# outfile -----------------------------------------------------------------
outpath = "_wgGesucht/analysis/output.csv"
if(!file.exists(outpath)) {
print("file does not exist")
df = data.frame(
price = NA,
location = NA,
id = NA,
size = NA
)
write_csv(df, outpath)
start = 9712560
} else{
df = read_csv(outpath)
start = df %>% filter(
if_all(everything(), ~!is.na(.x))
) %>% pull(id) %>% max
print("file exists reading...")
}
print(df)
# get the ids -------------------------------------------------------------
end = start + 50
start = 9712560
# get the ids -------------------------------------------------------------
end = start + 50
page_ids = start:end
rows = vector("list", length=length(page_ids))
i
i = 1
print(i)
id = page_ids[[i]]
url = glue("https://www.wg-gesucht.de/{id}.html" )
file = glue(tempfile(), ".html")
# download
download.file(url, file)
# read
html = rvest::read_html(file)
html
size = getSize(html) %>% as.numeric()
price = getPrice(html) %>% as.numeric()
location = getLocation(html) %>% as.character()
# source ------------------------------------------------------------------
source("_wgGesucht/analysis/utils.R")
source("analysis/utils.R")
size = getSize(html) %>% as.numeric()
size
price = getPrice(html) %>% as.numeric()
location = getLocation(html) %>% as.character()
price
i = 2
print(i)
id = page_ids[[i]]
url = glue("https://www.wg-gesucht.de/{id}.html" )
file = glue(tempfile(), ".html")
# download
download.file(url, file)
# read
html = rvest::read_html(file)
size = getSize(html) %>% as.numeric()
size
i = 3
for(i in seq_along(page_ids)){
print(i)
id = page_ids[[i]]
url = glue("https://www.wg-gesucht.de/{id}.html" )
file = glue(tempfile(), ".html")
# download
download.file(url, file)
# read
html = rvest::read_html(file)
size = getSize(html) %>% as.numeric()
print(size)
price = getPrice(html) %>% as.numeric()
location = getLocation(html) %>% as.character()
row = list(price = price, size = size, location = location, id = id)
rows[[i]] = row
}
i = 3
print(i)
id = page_ids[[i]]
url = glue("https://www.wg-gesucht.de/{id}.html" )
file = glue(tempfile(), ".html")
# download
download.file(url, file)
# read
html = rvest::read_html(file)
size = getSize(html) %>% as.numeric()
print(size)
html
url
file
id
size_node = html %>%
html_elements("h2.headline-key-facts") %>%
html_text() %>%
str_subset("m²")
size_node
size_node = html %>%
html_elements("h2.headline-key-facts") %>%
html_text()
size_node
size_node = html %>%
html_elements("h3.headline-key-facts") %>%
html_text()
size_node
str_match(size_node, "Zimmer")
str_detect(size_node, "Zimmer")
any(str_detect(size_node, "Zimmer"))
getWG = function(html){
size_node = html %>%
html_elements("h3.headline-key-facts") %>%
html_text()
wg = any(str_detect(size_node, "Zimmer"))
return(wg)
}
# get the ids -------------------------------------------------------------
end = start + 50
page_ids = start:end
rows = vector("list", length=length(page_ids))
for(i in seq_along(page_ids)){
print(i)
id = page_ids[[i]]
url = glue("https://www.wg-gesucht.de/{id}.html" )
file = glue(tempfile(), ".html")
# download
download.file(url, file)
# read
html = rvest::read_html(file)
size = getSize(html) %>% as.numeric()
price = getPrice(html) %>% as.numeric()
location = getLocation(html) %>% as.character()
wg = getWG(html)
print(paste0("WG: ", wg))
row = list(price = price, size = size, location = location, id = id, wg=wg)
rows[[i]] = row
}
rm(list=ls())
getSize = function(html){
size_node = html %>%
html_elements("h2.headline-key-facts") %>%
html_text() %>%
str_subset("m²")
if (length(size_node) == 0) {
return(NA_character_)
} else{
size = str_extract(size_node, "(\\d*)m") %>% gsub("m", "", .)
return(size)
}
}
library(tidyverse)
library(rvest)
library(glue)
rm(list=ls())
source("analysis/utils.R")
# outfile -----------------------------------------------------------------
outpath = "_wgGesucht/analysis/output.csv"
if(!file.exists(outpath)) {
print("file does not exist")
df = data.frame(
price = NA,
location = NA,
id = NA,
size = NA,
wg = NA
)
write_csv(df, outpath)
start = 9712560
} else{
df = read_csv(outpath)
start = df %>% filter(
if_all(everything(), ~!is.na(.x))
) %>% pull(id) %>% max
print("file exists reading...")
}
if(!file.exists(outpath)) {
print("file does not exist")
df = data.frame(
price = NA,
location = NA,
id = NA,
size = NA,
wg = NA
)
write.csv(df, outpath)
start = 9712560
} else{
df = read.csv(outpath)
start = df %>% filter(
if_all(everything(), ~!is.na(.x))
) %>% pull(id) %>% max
print("file exists reading...")
}
# get the ids -------------------------------------------------------------
end = start + 50
page_ids = start:end
start = 9712560
# get the ids -------------------------------------------------------------
end = start + 50
page_ids = start:end
rows = vector("list", length=length(page_ids))
for(i in seq_along(page_ids)){
print(i)
id = page_ids[[i]]
url = glue("https://www.wg-gesucht.de/{id}.html" )
file = glue(tempfile(), ".html")
# download
download.file(url, file)
# read
html = rvest::read_html(file)
size = getSize(html) %>% as.numeric()
price = getPrice(html) %>% as.numeric()
location = getLocation(html) %>% as.character()
wg = getWG(html)
print(paste0("WG: ", wg))
row = list(price = price, size = size, location = location, id = id, wg=wg)
rows[[i]] = row
}
i
url = paste0("https://www.wg-gesucht.de/", id ".html" )
url = paste0("https://www.wg-gesucht.de/", id, ".html" )
url
file = paste0(tempfile(), ".html")
file
for(i in seq_along(page_ids)){
print(i)
id = page_ids[[i]]
url = paste0("https://www.wg-gesucht.de/", id, ".html" )
file = paste0(tempfile(), ".html")
# download
download.file(url, file)
# read
html = rvest::read_html(file)
size = getSize(html) %>% as.numeric()
price = getPrice(html) %>% as.numeric()
location = getLocation(html) %>% as.character()
wg = getWG(html)
print(paste0("WG: ", wg))
row = list(price = price, size = size, location = location, id = id, wg=wg)
rows[[i]] = row
}
library(dplyr)
for(i in seq_along(page_ids)){
print(i)
id = page_ids[[i]]
url = paste0("https://www.wg-gesucht.de/", id, ".html" )
file = paste0(tempfile(), ".html")
# download
download.file(url, file)
# read
html = rvest::read_html(file)
size = getSize(html) %>% as.numeric()
price = getPrice(html) %>% as.numeric()
location = getLocation(html) %>% as.character()
wg = getWG(html)
print(paste0("WG: ", wg))
row = list(price = price, size = size, location = location, id = id, wg=wg)
rows[[i]] = row
}
library(stringr)
rows = vector("list", length=length(page_ids))
for(i in seq_along(page_ids)){
print(i)
id = page_ids[[i]]
url = paste0("https://www.wg-gesucht.de/", id, ".html" )
file = paste0(tempfile(), ".html")
# download
download.file(url, file)
# read
html = rvest::read_html(file)
size = getSize(html) %>% as.numeric()
price = getPrice(html) %>% as.numeric()
location = getLocation(html) %>% as.character()
wg = getWG(html)
print(paste0("WG: ", wg))
row = list(price = price, size = size, location = location, id = id, wg=wg)
rows[[i]] = row
}
library(rvest)
rows = vector("list", length=length(page_ids))
for(i in seq_along(page_ids)){
print(i)
id = page_ids[[i]]
url = paste0("https://www.wg-gesucht.de/", id, ".html" )
file = paste0(tempfile(), ".html")
# download
download.file(url, file)
# read
html = rvest::read_html(file)
size = getSize(html) %>% as.numeric()
price = getPrice(html) %>% as.numeric()
location = getLocation(html) %>% as.character()
wg = getWG(html)
print(paste0("WG: ", wg))
row = list(price = price, size = size, location = location, id = id, wg=wg)
rows[[i]] = row
}
# source ------------------------------------------------------------------
source("_wgGesucht/analysis/utils.R")
# outfile -----------------------------------------------------------------
outpath = "_wgGesucht/analysis/wgs.csv"
library(rvest)
library(glue)
library(dplyr)
library(stringr)
# source ------------------------------------------------------------------
source("_wgGesucht/analysis/utils.R")
# outfile -----------------------------------------------------------------
outpath = "_wgGesucht/analysis/wgs.csv"
if(!file.exists(outpath)) {
print("file does not exist")
df = data.frame(
price = NA,
location = NA,
id = NA,
size = NA,
wg = NA
)
write.csv(df, outpath)
} else{
df = read.csv(outpath)
start = df %>% filter %>% pull(id) %>% max(., na.rm=T)
print("file exists reading...")
}
start
# outfile -----------------------------------------------------------------
outpath = "_wgGesucht/analysis/wgs.csv"
if(!file.exists(outpath)) {
print("file does not exist")
df = data.frame(
price = NA,
location = NA,
id = NA,
size = NA,
wg = NA
)
write.csv(df, outpath)
} else{
df = read.csv(outpath)
start = df %>% filter %>% pull(id) %>% max(., na.rm=T)
print("file exists reading...")
}
outpath
outpath = here("analysis/wgs.csv")
library(here)
outpath = here("analysis/wgs.csv")
df = read.csv(outpath)
df
start = df %>% filter %>% pull(id) %>% max(., na.rm=T)
start
url="https://www.wg-gesucht.de/wg-zimmer-in-Wien.163.0.1.0.html?"
raw_html = read_html(url)
raw_html
raw_html %>% html_elements("h3 > a")
raw_html %>% html_elements("h3 > a") %>% .[[1]]
raw_html %>% html_elements("h3 > a") %>% .[[1]] %>% html_attr("href")
raw_html %>% html_elements("h3 > a") %>% map(~html_attr(.x, "href"))
library(tidyverse)
raw_html %>% html_elements("h3 > a") %>% lappy(~html_attr(.x, "href"))
raw_html %>% html_elements("h3 > a") %>% lapply(~html_attr(.x, "href"))
html_attr(x, "href")
raw_html %>% html_elements("h3 > a") %>% lapply(function(x){
html_attr(x, "href")
})
raw_html %>% html_elements("h3 > a") %>% lapply(function(x){
html_attr(x, "href")
}) %>% unlist
links = raw_html %>% html_elements("h3 > a") %>% lapply(function(x){
html_attr(x, "href")
}) %>% unlist
links
grepl("\\d{5,}", links)
grepl("[0-9]{5,}", links)
grepl("[0-9]{6,}", links)
grepl("[0-9]{7,}", links)
grepl("^\\/.*[0-9]{7,}", links)
wg_gesucht_links = grepl("^\\/.*[0-9]{7,}", links)
wg_gesucht_links
f = wg_gesucht_links[[1]]
f
links[wg_gesucht_links][[1]]
f = links[wg_gesucht_links][[1]]
f
gsub("\\d{5,}", "\\1", f)
f
gsub("(\\d{5,})", "\\1", f)
gsub("(\\[0-9]{5,})", "\\1", f)
gsub("(\\[0-9]{5,})", "\\2", f)
gsub("[^0-9]", "", f)
id = gsub("[^0-9]", "", f)
id
# source ------------------------------------------------------------------
source("_wgGesucht/analysis/utils.R")
start = findId()
source("./analysis/utils.R")
start = findId()
start
print(paste0("Start: ", start))
